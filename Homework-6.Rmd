---
title: "Homework_6"
author: "Mike Ament"
date: "February 19, 2020"
output: html_document
editor_options: 
  chunk_output_type: inline
---

###PART 1: (copied text from assignment) 

Read in data vector
To illustrate, we will generate some fake data here:

```{r}
library(ggplot2) # for graphics
library(MASS) # for maximum likelihood estimation

# quick and dirty, a truncated normal distribution to work on the solution set

z <- rnorm(n=3000,mean=0.2)
z <- data.frame(1:3000,z)
names(z) <- list("ID","myVar")
#z <- z[z$myVar>0,]
#str(z)
#summary(z$myVar)

```


In the third step of this exercise, you wil substitute in your own data for this fake data set. But for now, use the code chunks below to see how you "fit different statistical distributions to a vector of observations", and then estimate the maximum likelihood parameters for each distribution.

Plot histogram of data
Plot a histogram of the data, using a modification of the code from lecture. Here we are switching from qplot to ggplot for more graphics options. We are also rescaling the y axis of the histogram from counts to density, so that the area under the histogram equals 1.0.

```{r}

#p1 <- ggplot(data=z, aes(x=myVar, y=..density..)) +
  geom_histogram(color="grey60",fill="cornsilk",size=0.2) 
#p1
#print(p1)
```

Add empirical density curve
Now modify the code to add in a kernel density plot of the data. This is an empirical curve that is fitted to the data. It does not assume any particular probability distribution, but it smooths out the shape of the histogram:

```{r}
#p1 <-  p1 +  geom_density(linetype="dotted",size=0.75)
#print(p1)

```

Get maximum likelihood parameters for normal
Next, fit a normal distribution to your data and grab the maximum likelihood estimators of the two parameters of the normal, the mean and the variance:

```{r}
#normPars <- fitdistr(z$myVar,"normal")
#print(normPars)
#str(normPars)
#normPars$estimate["mean"] # note structure of getting a named attribute
#normPars$estimate["sd"]
```


###Plot normal probability density

Now let's call the dnorm function inside ggplot's stat_function to generate the probability density for the normal distribution. Read about stat_function in the help system to see how you can use this to add a smooth function to any ggplot. Note that we first get the maximum likelihood parameters for a normal distribution fitted to thse data by calling fitdistr. Then we pass those parameters (meanML and sdML to stat_function:

```{r}
#meanML <- normPars$estimate["mean"] ## pass these to the stat_function
#sdML <- normPars$estimate["sd"]

#xval <- seq(0,max(z$myVar),len=length(z$myVar)) ## spaces it evenly 

 #stat <- stat_function(aes(x = xval, y = ..y..), fun = dnorm, colour="red", n = length(z$myVar), args = list(mean = meanML, sd = sdML))
 #p1 + stat
 
```

Notice that the best-fitting normal distribution (red curve) for these data actually has a biased mean. That is because the data set has no negative values, so the normal distribution (which is symmetric) is not working well.

###Plot exponential probability density

Now let's use the same template and add in the curve for the exponential:

```{r}
#expoPars <- fitdistr(z$myVar,"exponential")
#rateML <- expoPars$estimate["rate"]

#stat2 <- stat_function(aes(x = xval, y = ..y..), fun = dexp, colour="blue", n = length(z$myVar), args = list(rate=rateML))
 #p1 + stat + stat2
```


### Plot uniform probability density
 
For the uniform, we don't need to use fitdistr because the maximum likelihood estimators of the two parameters are just the minimum and the maximum of the data:

```{r}
#stat3 <- stat_function(aes(x = xval, y = ..y..), fun = dunif, colour="darkgreen", n = length(z$myVar), args = list(min=min(z$myVar), max=max(z$myVar)))
 #p1 + stat + stat2 + stat3
```

### Plot gamma probability density, fits well 

```{r}
#gammaPars <- fitdistr(z$myVar,"gamma")
#shapeML <- gammaPars$estimate["shape"]
#rateML <- gammaPars$estimate["rate"]

#stat4 <- stat_function(aes(x = xval, y = ..y..), fun = dgamma, colour="brown", n = length(z$myVar), args = list(shape=shapeML, rate=rateML))
 #p1 + stat + stat2 + stat3 + stat4
```

Plot beta probability density

This one has to be shown in its own plot because the raw data must be rescaled so they are between 0 and 1, and then they can be compared to the beta.

```{r}
#pSpecial <- ggplot(data=z, aes(x=myVar/(max(myVar + 0.1)), y=..density..)) +
 # geom_histogram(color="grey60",fill="cornsilk",size=0.2) + 
 # xlim(c(0,1)) +
#  geom_density(size=0.75,linetype="dotted")

#betaPars <- fitdistr(x=z$myVar/max(z$myVar + 0.1),start=list(shape1=1,shape2=2),"beta")
#shape1ML <- betaPars$estimate["shape1"]
#shape2ML <- betaPars$estimate["shape2"]

#statSpecial <- stat_function(aes(x = xval, y = ..y..), fun = dbeta, colour="orchid", n = length(z$myVar), args = list(shape1=shape1ML,shape2=shape2ML))
#pSpecial + statSpecial
```


###PART 2: 

(Prompt)
Once the code is in and runs, try running this analysis on your own data (or data from your lab). Find a vector of data (of any size), set it up in a .csv file, and read the data into a data frame with this code chunk:




```{r}
#I borrowed data from online database PlantGrowth 

library(datasets)
data(PlantGrowth)
#summary(PlantGrowth)
#head(PlantGrowth)
z<- PlantGrowth
myVar<- z$weight  ## I called it myVar so I wouldn't have to change too much of the old code 
#str(z)

p1 <- ggplot(data=z, aes(x=myVar, y=..density..)) +
  geom_histogram(color="grey60",fill="cornsilk",size=0.2) 

# empiracle density curve 

p1 <-  p1 +  geom_density(linetype="dotted",size=0.75)

### Getting Max liklihood parameters 

normPars <- fitdistr(myVar,"normal")
#str(normPars)
normPars$estimate["mean"] # note structure of getting a named attribute
normPars$estimate["sd"]

### Adding normal prob. density distribution 

meanML <- normPars$estimate["mean"] ## pass these to the stat_function
sdML <- normPars$estimate["sd"]

xval <- seq(0,max(myVar),len=length(myVar)) ## spaces it evenly 

 stat <- stat_function(aes(x = xval, y = ..y..), fun = dnorm, colour="red", n = length(myVar), args = list(mean = meanML, sd = sdML))
 p1 + stat

 ## Add exponential probabilty density curve 
 
 expoPars <- fitdistr(myVar,"exponential")
rateML <- expoPars$estimate["rate"]

stat2 <- stat_function(aes(x = xval, y = ..y..), fun = dexp, colour="blue", n = length(myVar), args = list(rate=rateML))
 p1 + stat + stat2
 
 ## Add uniform probability density curve 
 
 stat3 <- stat_function(aes(x = xval, y = ..y..), fun = dunif, colour="darkgreen", n = length(myVar), args = list(min=min(myVar), max=max(myVar)))
 p1 + stat + stat2 + stat3
 

## Add gamma probability density curve

 gammaPars <- fitdistr(myVar,"gamma")
shapeML <- gammaPars$estimate["shape"]
rateML <- gammaPars$estimate["rate"]

stat4 <- stat_function(aes(x = xval, y = ..y..), fun = dgamma, colour="brown", n = length(myVar), args = list(shape=shapeML, rate=rateML))
 p1 + stat + stat2 + stat3 + stat4
 
```

###PART 4: 
(Prompt) 
Take a look at the second-to-last graph which shows the histogram of your data and 4 probability density curves (normal, uniform, exponential, gamma) that are fit to the data. The beta distribution in the final graph is somewhat special. It often fits the data pretty well, but that is because we have assumed the largest data point is the true upper bound, and everything is scaled to that. The fit of the uniform distribution also fixes the upper bound. The other curves (normal, exponential, and gamma) are more realistic because they do not have an upper bound. For most data sets, the gamma will probably fit best, but if you data set is small, it may be very hard to see much of a difference between the curves.  

(Answer) 
The gamma and normal distributions fit my data the best. The the center of the normal distribution, however, is slightly closer to the mean of my data. Either distribution would probably be fine but I'm going to go with the normal distribution for this problem. 


###PART 5:
(Prompt) 
Using the best-fitting distribution, go back to the code and get the maximum likelihood parameters. Use those to simulate a new data set, with the same length as your original vector, and plot that in a histogram and add the probability density curve. Right below that, generate a fresh histogram plot of the original data, and also include the probability density curve. 
(Answer) 

```{r}

w <- rnorm(n=length(myVar),mean=meanML, sd=sdML) ## I'm using a normal distribution, which I identified as the best fitting distribution above, and I'm using the mean and sd of my sample data to inform the new dataset.  n = the length of the PlantGrowth dataset. 

w <- data.frame(1:length(myVar),w)
names(w) <- list("ID","sim_weight")
w <- w[w$sim_weight>0,]
s<- w$sim_weight
#str(w)
#summary(w$sim_weight)

## Histogram 

h <- ggplot(data=w, aes(x=s, y=..density..)) +
  geom_histogram(color="grey60",fill="cornsilk",size=0.2) 


## Get maxiumum likelihood parameters 


normPars <- fitdistr(s,"normal")
#print(normPars)
#str(normPars)
normPars$estimate["mean"] # note structure of getting a named attribute
normPars$estimate["sd"]

### Add probability density curve 

meanML <- normPars$estimate["mean"] ## pass these to the stat_function
sdML <- normPars$estimate["sd"]

xval <- seq(0,max(s),len=length(s)) ## spaces it evenly 

 stat <- stat_function(aes(x = xval, y = ..y..), fun = dnorm, colour="red", n = length(s), args = list(mean = meanML, sd = sdML))
 h + stat
 
 

```

###The graph above is my simulated data generated from the parameters estimates (mean, sd)

### The graph below is my original data with the normal probability density distribution 

```{r}
p1 <- ggplot(data=z, aes(x=myVar, y=..density..)) +
  geom_histogram(color="grey60",fill="cornsilk",size=0.2) 


### Getting Max liklihood parameters 

normPars <- fitdistr(myVar,"normal")
#print(normPars)
#str(normPars)
normPars$estimate["mean"] # note structure of getting a named attribute
normPars$estimate["sd"]

### Adding normal prob. density distribution 

meanML <- normPars$estimate["mean"] ## pass these to the stat_function
sdML <- normPars$estimate["sd"]

xval <- seq(0,max(myVar),len=length(myVar)) ## spaces it evenly 

 stat <- stat_function(aes(x = xval, y = ..y..), fun = dnorm, colour="red", n = length(myVar), args = list(mean = meanML, sd = sdML))
 p1 + stat

```


###PART 6: 
(Prompt)
How do the two histogram profiles compare? Do you think the model is doing a good job of simulating realistic data that match your original measurements? Why or why not?

(Answer) Wow! The two histograms look very similar, the model is doing a great job simulating data. The centers of the distribution (mean) are almost identical and the spread of the data looks comparable. 

(Prompt)
If you have entered a large data frame with many columns, try running all of the code on a different variable to see how the simulation performs.

My data only had one variable, sorry!



